{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobility Data Analysis\n",
    "1. Scoping\n",
    "2.  Preprocress the data\n",
    "3. Explolatory Data Analysis (EDA)\n",
    "4. Generate user trips and other user attributes\n",
    "5. Perfom analysis of user data to generate individual level metrics\n",
    "6. Generate aggregate metrics such as OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Scoping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Python setup\n",
    "Heree, we import all the required Python packages. In order to use, \n",
    "any other module which wasnt ```pip``` installed, such as ```mob_data_utils```,\n",
    "you  can do the following:\n",
    "```sys.append(full_path_to_module)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/eze/Documents/mk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import  to_timestamp, to_date\n",
    "#import pandas as pd\n",
    "#import random\n",
    "from pathlib import Path\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "import random\n",
    "from pyspark.sql.functions import col, unix_timestamp, date_format as spark_date_format\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, min, max, datediff, to_date, substring, countDistinct, count, mean, sqrt, pow\n",
    "from pyspark.sql.types import TimestampType, StringType\n",
    "import numpy as np\n",
    "import glob\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Modify the path to point to the directory containing mob_data_utils.py\n",
    "# Assuming mob_data_utils.py is directly inside the TDA folder\n",
    "mob_dir = os.path.join(DATA_DIR, \"mob_data_utils.py\")\n",
    "sys.path.append(mob_dir)\n",
    "\n",
    "import mob_data_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup working directories\n",
    "Its also important to setup commonly used diretories such as where you will be saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup global parameters and variables\n",
    "MISC_PROCESSING_PARAMS = {'distance_threshold': 2, 'min_unique_locs': 2,'datetime_col': 'datetime',\n",
    "                        'userid': 'user_id','x': 'lon', 'y': 'lat'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing.\n",
    "Often, after all the data has been  acquired, thee next step is to do some preprocessing on the raw data. \n",
    "The objectives of this task will vary depending on the data analysis goals but some of them include following:\n",
    "- **Sanitize the data:** this data cleaning has to be done carefully to avoid introducing errors but its often a necessary step. It can involve dropping some unnecessary variables/columns. Renaming some columns to something which makes more sense. Dropping some observations. For instance, in this analysis where location and time-stamp is important, dropping all observations with no time-stamp and no location is required.\n",
    "- **Create new variables:**. If necessary, this is also the time transform some variables from a format which is not convinient for your analysis. For instance, converting string time variables to datetime aware variables.\n",
    "- **Combine datasets:** If you have more than one dataset, during preprocessing, you can also combine several datasets into one. For instance, we have the CDR transations which have no location details. We bring in the location details from another file.\n",
    "- **Filtering based on columns and observations:** This can be done through any of the stages mentioned above but its worth mentioning that often, you may drop some columns which arent useful for your analysis. Also, you may drop some observations based on some conditions depending on your analysis needs.\n",
    "\n",
    "Unlike in other data collection domains such as surveys where you can have standard data processing steps, in the data science space where your dataset can be anything, there are no hard and fast rule for preprocessing and data cleaning. It will be a case by case basis depending on your analysis goals. Also, preprocessing isnt necessarily a linear process: depending on what results you get downstream, you can go back and modify the preprocesisng steps. In this project, we have the ```preprocess_cdrs_using_spark``` which takes raw cdrs and saves to a CSV a processed dataset. Alternatively, we can return a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_cdrs_using_spark(file_or_folder=None, number_of_users_to_sample=None,\n",
    "                                output_csv=None, date_format='yyyyMMddHHmmss',\n",
    "                                debug_mode=True, loc_file=None, save_to_csv=False):\n",
    "    \"\"\"\n",
    "    In this function, we perfom some basic preprocessing such as below:\n",
    "    1. rename columns\n",
    "    2. change some data types\n",
    "    3. Add location details\n",
    "    Eventually, we will sample the data to use for our analysis\n",
    "    :param data_folder:\n",
    "    :param output_csv_for_sample_users:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # create a SparkSession object\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"CDR Preprocessing\") \\\n",
    "        .config(\"spark.driver.memory\", \"10g\") \\\n",
    "        .config(\"spark.executor.memory\", \"10g\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # read data with spark\n",
    "    df = spark.read.option(\"header\", \"true\").csv(file_or_folder)\n",
    "    df.printSchema()\n",
    "    \n",
    "    # repartition to speed up\n",
    "    df = df.repartition(20)\n",
    "    \n",
    "    # if just testing/debugging, pick only a small dataset\n",
    "    # by using the sample function of spark\n",
    "    if debug_mode:\n",
    "        dfs = df.sample(fraction=0.3) \n",
    "        df = dfs\n",
    "    \n",
    "    # rename columns to remove space and name them using camel\n",
    "    # case  sytle like this: cdr datetime becomes cdrDatetime\n",
    "    # calling phonenumber becomes just phoneNumber\n",
    "    # if you are renaming more than one column, you can\n",
    "    # chain the commands and add round brackets like this:\n",
    "    df2 = df.withColumnRenamed(\"cdr type\", \"cdrType\") \\\n",
    "           .withColumnRenamed(\"cdr datetime\", \"cdrDatetime\") \\\n",
    "           .withColumnRenamed(\"last calling cellid\", \"lastCallingCellId\") \\\n",
    "           .withColumnRenamed(\"call duration\", \"callDuration\") \\\n",
    "           .withColumnRenamed(\"user_id\", \"userId\")\n",
    "    \n",
    "    # drop the 'cdr type' column\n",
    "    df3 = df2.drop(\"cdrType\")\n",
    "    \n",
    "    # Use Spark UDF to add date and datetime\n",
    "    add_datetime = None\n",
    "    add_date = None\n",
    "    # create timestamp\n",
    "    df4 = None\n",
    "    df5 = format_cdr_datetime(df3, date_format)\n",
    "    \n",
    "    # lets make sure we dont have any null phoneNumbers\n",
    "    # use spark filter() function to remove null phoneNumbers\n",
    "    df6 = df5.filter(col(\"cdrDatetime\").isNotNull() &\n",
    "                   col(\"lastCallingCellId\").isNotNull() &\n",
    "                   col(\"userId\").isNotNull())\n",
    "    \n",
    "    # Lets merge with location details using cellId from CDRs and also\n",
    "    # cellID on the other\n",
    "    # read pandas dataframe of location details\n",
    "    dfLoc = pd.read_csv(loc_file)\n",
    "    \n",
    "    \n",
    "    # rename column 'cell_id' to 'cellId' in the pandas dataframe\n",
    "    # YOUR CODE\n",
    "    dfLoc.rename(columns={'cell_id': 'cellId'}, inplace=True)\n",
    "    \n",
    "    # create spark dataframe from the pandas dataframe\n",
    "    sdfLoc = sdfLoc = spark.createDataFrame(dfLoc)\n",
    "    \n",
    "    # join the cdrs dataframe with the location dataframe\n",
    "    df7 = df6.join(sdfLoc, df6[\"lastCallingCellId\"] == sdfLoc[\"cellId\"], \"left\")\n",
    "    \n",
    "    # create a list of unique user phoneNumbers\n",
    "        \n",
    "    all_users = df7.select(\"userId\").distinct().collect()\n",
    "    \n",
    "    # randomly select the required number of users\n",
    "    # using the random.choices() function\n",
    "    if number_of_users_to_sample is not None:\n",
    "        random_user_numbers = random.choices(all_users, k=min(number_of_users_to_sample, len(all_users)))\n",
    "        dfu = df7.filter(col(\"userId\").isin(random_user_numbers) )\n",
    "    else:\n",
    "        dfu = df7\n",
    "    # select only our random user data using spark filter\n",
    "    # or the type of sampling we did in assignment-2\n",
    "    dfu = df7.filter(col(\"lat\").isNotNull() & col(\"lon\").isNotNull())\n",
    "    \n",
    "    # save to CSV if necessary\n",
    "    # replace pass and Noen with your code \n",
    "    if save_to_csv:\n",
    "        print(f\"Saving processed data into {output_csv}...\")\n",
    "        dfu.write.csv(output_csv, header=True, mode=\"overwrite\")\n",
    "        print(f\"Data well saved into {output_csv}.\")\n",
    "    \n",
    "    return dfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to formatted the date\n",
    "\n",
    "def format_cdr_datetime(df, date_format):\n",
    "    \"\"\"\n",
    "    Formats the 'cdrDatetime' column to a timestamp and adds 'date' and 'cdrDatetime' columns.\n",
    "\n",
    "    :param df: Input DataFrame containing 'cdrDatetime'\n",
    "    :param date_format: The format for parsing 'cdrDatetime'\n",
    "    :return: DataFrame with 'timestamp', 'date', and formatted 'cdrDatetime' columns added\n",
    "    \"\"\"\n",
    "    if df.schema[\"cdrDatetime\"].dataType.typeName() == \"long\":\n",
    "        df = df.withColumn(\"cdrDatetime\", col(\"cdrDatetime\").cast(\"string\"))\n",
    "\n",
    "    # Convert cdrDatetime to timestamp\n",
    "    df = df.withColumn(\"timestamp\", unix_timestamp(col(\"cdrDatetime\"), date_format).cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"date\", spark_date_format(col(\"timestamp\"), \"yyyy-MM-dd\"))\n",
    "    df = df.withColumn(\"cdrDatetime\", spark_date_format(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cdr type: string (nullable = true)\n",
      " |-- cdr datetime: string (nullable = true)\n",
      " |-- call duration: string (nullable = true)\n",
      " |-- last calling cellid: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n",
      "Saving processed data into /home/eze/Documents/mk/processed_cdrs_output...\n",
      "Data well saved into /home/eze/Documents/mk/processed_cdrs_output.\n",
      "+-------------------+------------+-----------------+-------------------+-------------------+----------+-------+------+---------+---------+\n",
      "|        cdrDatetime|callDuration|lastCallingCellId|             userId|          timestamp|      date|site_id|cellId|      lat|      lon|\n",
      "+-------------------+------------+-----------------+-------------------+-------------------+----------+-------+------+---------+---------+\n",
      "|2018-07-10 20:03:56|        NULL|          34821.0|6501306397541813347|2018-07-10 20:03:56|2018-07-10|   S224| 34821|-8.528478|26.743777|\n",
      "|2018-07-10 20:04:30|        NULL|          34821.0|8081674521475362040|2018-07-10 20:04:30|2018-07-10|   S224| 34821|-8.528478|26.743777|\n",
      "|2018-07-02 20:20:41|        NULL|          34821.0| 266199535233139471|2018-07-02 20:20:41|2018-07-02|   S224| 34821|-8.528478|26.743777|\n",
      "|2018-07-02 20:11:35|        NULL|          34821.0|7585349290893780652|2018-07-02 20:11:35|2018-07-02|   S224| 34821|-8.528478|26.743777|\n",
      "|2018-07-11 20:51:49|        NULL|          34821.0| 607991208890936565|2018-07-11 20:51:49|2018-07-11|   S224| 34821|-8.528478|26.743777|\n",
      "+-------------------+------------+-----------------+-------------------+-------------------+----------+-------+------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use DATA_DIR and joinpath as its been used above to create\n",
    "\n",
    "# full path for simulated_cdrs and loc file\n",
    "loc_file = os.path.join(DATA_DIR, \"simulated_locs.csv\")\n",
    "cdrs_dir = os.path.join(DATA_DIR, \"simulated_cdrs\")\n",
    "num_users = None\n",
    "debug = False\n",
    "datetime_fmt = None\n",
    "output_csv = os.path.join(DATA_DIR, \"processed_cdrs_output\")\n",
    "\n",
    "# call preprocess_cdrs_using_spark here\n",
    "# use cache() at the end of the like this preprocess_cdrs_using_spark.cache()\n",
    "# Learn about what cache does using spark here:\n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.cache.html#pyspark.sql.DataFrame.cache\n",
    "dfu = preprocess_cdrs_using_spark(file_or_folder=cdrs_dir, number_of_users_to_sample=num_users,\n",
    "                                output_csv=output_csv, date_format='yyyyMMddHHmmss',\n",
    "                                debug_mode=False, loc_file=loc_file, save_to_csv=True).cache()\n",
    "\n",
    "dfu.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explolatory Data Analysis (EDA)\n",
    "Whether the end result of your project is to produce a statistical report or \n",
    "to build a prediction model to be put in production, EDA is an essential stage in any data science project. EDA can be defined as \n",
    "the process of performing initial investigations on data so as to discover patterns,to spot anomalies,\n",
    "to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n",
    "It is a good practice to understand the data first and try to gather as many insights from it. \n",
    "EDA is all about making sense of data before using the data for the intended use (e.g., build ML models, perfom statisitcal analysis). \n",
    "\n",
    "Again, there arent hard and fast rules on how to perfom EDA but some of the specific quesitons you would like to answer are as folloes:\n",
    "- For each variable in the data, whats its distribution? Is it skewed? Whats its data type? Is it an approapriate  data type fopr my analysis. Are there any outliers?\n",
    "- Whats the relationship between variables?\n",
    "\n",
    "In this project, we will use the ```explore_data``` and explore what functions Spark has for basic EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate more summary statistics\n",
    "Please complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def summary_stats_for_user_events(spark_df, out_stats):\n",
    "    \"\"\"\n",
    "    In this function, the goal is to take a big Spark\n",
    "    DataFrame, group users and count each users events, \n",
    "    convert to pandas DataFrame and generate summary stats\n",
    "    :param: spark_df: preprocessed spark dataframe with data for multiple users\n",
    "    :param: out_stats: CSV file path to save  the summary stats\n",
    "    \"\"\"\n",
    "    # group user and count number of events\n",
    "    df_grouped = spark_df.groupBy(\"userId\").agg(count(\"*\").alias(\"num_events\"))\n",
    "    # convert resulting spark dataframe to pandas\n",
    "    pdf = df_grouped.toPandas()\n",
    "    # change column \"count\" to num_events,remember that pdf is a pandas DataFrame\n",
    "    pdf = pdf.rename(columns={'count':'num_events'})\n",
    "    \n",
    "    # generate summary stats using pandas describe() function\n",
    "    # use property T to transpose the describe results and convert them\n",
    "    # into a DataFrame like this: pd.DataFrame(transposed describe results).reset_index()\n",
    "    # Dont forget to rese_index()\n",
    "    pdf_sum_stats = pd.DataFrame(pdf['num_events'].describe().T).reset_index()\n",
    "    \n",
    "    # remove the first row which has value \"count\"\n",
    "    # you can use list indexing to achieve this\n",
    "    pdf_sum_stats = pdf_sum_stats.iloc[1:]\n",
    "    \n",
    "    # Rename the column index into something informative. For instance, \"Stat\"\n",
    "    pdf_sum_stats = pdf_sum_stats.rename(columns={'index':'Stat'})\n",
    "    \n",
    "    # Rename the percentiles in numbers to something better\n",
    "    # first, declare a dict with old and new names\n",
    "    percentile_mapping = {\n",
    "        '25%':'25th_percentile',\n",
    "        '50%':'median',\n",
    "        '75%':'75th_percentile'\n",
    "    }\n",
    "    # next, update the Stats column using the pd.Series.map() function\n",
    "    pdf_sum_stats['Stat'] = pdf_sum_stats['Stat'].map(percentile_mapping).fillna(pdf_sum_stats['Stat'])\n",
    "\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    print(\"This is the summary statistics table.\")\n",
    "    print(\"=\"*40)\n",
    "    print()\n",
    "    # please print  the table  below\n",
    "    print(pdf_sum_stats)\n",
    "    \n",
    "    # Now  save the summary stats to CSV\n",
    "    print(f\"Saving processed data into {out_stats}...\")\n",
    "    pdf_sum_stats.to_csv(out_stats, index=False)\n",
    "    print(f\"Data well saved into {out_stats}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_days_in_dataset(spark_df):\n",
    "    \"\"\"\n",
    "    This function finds the total days in the dataset using the cdrDatetime column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the min and max date in dataset using spark aggregate function\n",
    "    min_date = spark_df.select(min(\"date\"))\n",
    "    max_date = spark_df.select(max(\"date\"))\n",
    "\n",
    "    # compute the difference in days using spark function datediff()\n",
    "    days = spark_df.select(datediff(max(\"date\"),min(\"date\")).alias(\"day_diff\")).first()[0]\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "This is the summary statistics table.\n",
      "========================================\n",
      "\n",
      "              Stat    num_events\n",
      "1             mean     15.333054\n",
      "2              std     37.955597\n",
      "3              min      1.000000\n",
      "4  25th_percentile      2.000000\n",
      "5           median      4.000000\n",
      "6  75th_percentile     14.000000\n",
      "7              max  22122.000000\n",
      "========================================\n",
      "Total days in dataset: 15\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "if dfu:\n",
    "    out_stats_file = os.path.join(DATA_DIR, \"user_event_stats.csv\")\n",
    "    summary_stats_for_user_events(dfu, out_stats_file)\n",
    "\n",
    "    days = total_days_in_dataset(dfu)+1\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Total days in dataset:\", days)\n",
    "    print(\"=\" * 40)\n",
    "else:\n",
    "    print(\"No dataframe to process, please ensure you are not saving to csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate individual based mobility patterns and attributes\n",
    "As we noted in the project  instructions, the focus of this analysis is to understand mobility patterns \n",
    "on individual users. Although, generating trips  and understanding their distribution is crucial for this project, due to time constraints, we will start with simple mobility metrics. Namely:\n",
    "- **Radius of gyration(Rg):**  For a single day, Rg can be defined in simple terms as the maximum distance a user travels. We can then compute ```avg_Rg``` based on all Rg from the user's data. This metric ```avg_Rg``` is what we will compute.\n",
    "- **Number of unique locations visited everyday:** As the name suggests, this is simply, the count of unique locations an individual visits everyday. Given multiple days data, we will compute the ```avg_locs_per_day```\n",
    "\n",
    "In addition to the mobility metric above, we will report the ```number of days``` a user was activive which will help us understand how much we should trust user data. \n",
    "\n",
    "For this task, we will utilize functions in the ```mob_data_utils``` module which were already created to generate  the required metrics above. You can import ```mob_data_utils``` like this to use my code: \n",
    "```import mob_data_utils as ut```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to generate user attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_basic_user_mob_attributes(df, output_file=None):\n",
    "        \"\"\"\n",
    "        In this funciton, we generate some basic user attributes \n",
    "        to help further explore the data and also report on \n",
    "        individual mobility metrics.\n",
    "        :param df: Pandas DataFrame of single user data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # get, datecol, x(lon), y(lat) from the MISC_PROCESSING_PARAMS variable\n",
    "        datetimecol = MISC_PROCESSING_PARAMS['datetime_col']\n",
    "        x =  MISC_PROCESSING_PARAMS['x']\n",
    "        y =  MISC_PROCESSING_PARAMS['y']\n",
    "        \n",
    "        # use if condition to \n",
    "        if  'date' not in df.columns:\n",
    "            # add date column in case its not  there\n",
    "            # use the datetimecol to achieve this\n",
    "            df['date'] = df[datetimecol].dt.date\n",
    "        \n",
    "        # get a list of all  days/dates in ascending order\n",
    "        # first, sort the dates and then get only unique dates\n",
    "        dates = sorted(df['date'].unique())\n",
    "        # this dictionary will keep, for each, a count of unique locations visited\n",
    "        # initialize this dict with dates as keys and values set to 0\n",
    "        # you can use list comprehension idea though this is a dictionary\n",
    "        # Hint, create a list  of unique dates when initializing this dict\n",
    "        unique_locs_by_day = {date: 0 for date in dates}\n",
    "        \n",
    "        # create a dictionary just like above but this one will keep\n",
    "        # maximum distance travelled for each day\n",
    "        dates_dist = {date: 0 for date in dates} \n",
    "        \n",
    "        # Loop through the dates_dist dictionary\n",
    "        for date in dates: \n",
    "            # Filter the input df so that we only get data for this date\n",
    "            dfd = df[df['date'] == date]\n",
    "\n",
    "            # get number of unique locations for this day\n",
    "            uniq_xy = ut.va_generate_unique_locs(df=dfd, x=x, y=y)\n",
    "            # add to the unique_locs_by_day dict, this date based on how\n",
    "            # you initialized your loop, the value is the number of\n",
    "            # unique locations visited\n",
    "            unique_locs_by_day[date] = len(uniq_xy)\n",
    "\n",
    "\n",
    "            # distances travel\n",
    "            if len(uniq_xy) > 1:\n",
    "                dist_mtx = ut.va_distance_matrix(uniq_xy)\n",
    "                # From the distance matrix above, get only columns with \"to\"\n",
    "                # in it, use list comprehension with if condition\n",
    "                req_cols = [col for col in dist_mtx.columns if \"to\" in col]\n",
    "                # get max value from the distance matrix above\n",
    "                # first, subset the dist_mtx DataDrame by selecting only req_cols\n",
    "                # then, get values from the resulting DataFrame which you should\n",
    "                # pass into np.max() function\n",
    "                # put the resulting max value into the dates_dist dict with this \n",
    "                # date as key\n",
    "                # this can be achieved in a single line of code or multiple lines\n",
    "                dates_dist[date] = np.max(dist_mtx[req_cols].values)\n",
    "            else:\n",
    "                # if number of unique locations is less than or equal to 1\n",
    "                # then set the value in the dates_dist dict accordingly\n",
    "                dates_dist[date] = 0\n",
    "                \n",
    "        # Prepare results for saving\n",
    "        results_df = pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'unique_locations': [unique_locs_by_day[date] for date in dates],\n",
    "            'max_distance': [dates_dist[date] for date in dates]\n",
    "        })\n",
    "        \n",
    "        number_of_days = len(dates)\n",
    "\n",
    "        # Save results to a CSV file if an output file path is provided\n",
    "        if output_file:\n",
    "            print(f\"Saving processed data into {output_file}...\")\n",
    "            results_df.to_csv(output_file, index=False)\n",
    "            \n",
    "            print(f\"Data well saved into {output_file}.\")\n",
    "\n",
    "        \n",
    "        return dates_dist, unique_locs_by_day, number_of_days\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'2018-06-29': 425.2907455105583,\n",
       "  '2018-06-30': 425.2907455105583,\n",
       "  '2018-07-01': 425.2907455105583,\n",
       "  '2018-07-02': 425.2907455105583,\n",
       "  '2018-07-03': 425.2907455105583,\n",
       "  '2018-07-04': 425.2907455105583,\n",
       "  '2018-07-05': 425.2907455105583,\n",
       "  '2018-07-06': 425.2907455105583,\n",
       "  '2018-07-07': 425.2907455105583,\n",
       "  '2018-07-08': 425.2907455105583,\n",
       "  '2018-07-09': 425.2907455105583,\n",
       "  '2018-07-10': 425.2907455105583,\n",
       "  '2018-07-11': 425.2907455105583,\n",
       "  '2018-07-12': 425.2907455105583,\n",
       "  '2018-07-13': 425.2907455105583},\n",
       " {'2018-06-29': 84,\n",
       "  '2018-06-30': 84,\n",
       "  '2018-07-01': 84,\n",
       "  '2018-07-02': 84,\n",
       "  '2018-07-03': 84,\n",
       "  '2018-07-04': 84,\n",
       "  '2018-07-05': 84,\n",
       "  '2018-07-06': 85,\n",
       "  '2018-07-07': 85,\n",
       "  '2018-07-08': 85,\n",
       "  '2018-07-09': 85,\n",
       "  '2018-07-10': 85,\n",
       "  '2018-07-11': 85,\n",
       "  '2018-07-12': 85,\n",
       "  '2018-07-13': 85},\n",
       " 15)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    " \n",
    "directory_path = os.path.join(DATA_DIR, \"processed_cdrs_output/\")\n",
    "\n",
    "# Use glob to find all CSV files in the directory\n",
    "file_pattern = os.path.join(directory_path, '*.csv')\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Read and concatenate all CSV files into a single DataFrame\n",
    "dfu = pd.concat((pd.read_csv(file) for file in csv_files), ignore_index=True)\n",
    "outcsv = os.path.join(DATA_DIR, \"basic_user_attributes.csv\")\n",
    "\n",
    "# Now  the combined DataFrame to your function\n",
    "results = get_basic_user_mob_attributes(dfu, outcsv)\n",
    "\n",
    "# Display or process the results as needed\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Choice of  the mean radius of gyration\n",
    "   \n",
    "   \n",
    "   \n",
    "   The avg_Rg represents the mean radius of gyration, a metric used to measure the spatial spread of an individual’s movement. It provides insights into how far an individual typically moves from a central point (e.g., home or office). In the context of this dataset, it can help analyze user mobility patterns across different cell towers or geographic locations.\n",
    "    \n",
    "#### Why is avg_Rg Relevant?\n",
    "\n",
    "   **Mobility Patterns:** It quantifies the extent of a user’s mobility, which is particularly useful for applications such as urban planning, transportation analysis, and monitoring public health policies.\n",
    "    Correlation with Other Metrics: When correlated with avg_locs_per_day, it can provide insights into whether users with more locations visited per day also tend to have higher mobility spreads.\n",
    "\n",
    "#### How is avg_Rg Typically Calculated?\n",
    "\n",
    "   **For each user:**\n",
    "        Compute the geographic centroid (e.g., mean latitude and longitude) of all visited locations.\n",
    "        Calculate the squared distance of each location from the centroid.\n",
    "        Average these squared distances and take the square root to get the radius of gyration.\n",
    "\n",
    "   **For all users:**\n",
    "        Compute the average of these individual radii of gyration to get avg_Rg.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use spark instead of pandas\n",
    "\n",
    "# Define function to calculate user mobility attributes\n",
    "def generate_basic_user_attributes_with_spark(input_folder, outcsv, num_events_threshold=None):\n",
    "    \"\"\"\n",
    "    Generate basic user attributes to explore individual mobility metrics.\n",
    "    :param input_folder: Folder containing input CSV files\n",
    "    :param outcsv: Output CSV file path\n",
    "    :param num_events_threshold: Minimum number of events per user to include\n",
    "    :return: Spark DataFrame with user attributes\n",
    "    \"\"\"\n",
    "    # Initialize Spark session\n",
    "    spark = SparkSession.builder.appName(\"UserMobilityAnalysis\").getOrCreate()\n",
    "\n",
    "    # Read all CSV files in the folder into a single DataFrame\n",
    "    df = spark.read.csv(os.path.join(input_folder, \"*.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "    # Calculate radius of gyration for each row\n",
    "    df = df.withColumn(\"squared_distance\", pow(col(\"lat\") - mean(\"lat\").over(Window.partitionBy(\"userId\")), 2) + \\\n",
    "                                         pow(col(\"lon\") - mean(\"lon\").over(Window.partitionBy(\"userId\")), 2))\n",
    "    df = df.withColumn(\"radius_gyration\", sqrt(mean(\"squared_distance\").over(Window.partitionBy(\"userId\"))))\n",
    "\n",
    "    # Calculate basic user mobility metrics\n",
    "    user_attributes = (\n",
    "        df.groupBy(\"userId\")\n",
    "          .agg(\n",
    "              countDistinct(\"date\").alias(\"usage_days\"),\n",
    "              (count(\"cellId\") / countDistinct(\"date\")).alias(\"mean_locs_per_day\"),\n",
    "              mean(\"radius_gyration\").alias(\"avg_Rg\"),\n",
    "              mean(\"lat\").alias(\"avg_latitude\"),\n",
    "              mean(\"lon\").alias(\"avg_longitude\")\n",
    "          )\n",
    "    )\n",
    "\n",
    "    # Apply event threshold filter if specified\n",
    "    if num_events_threshold:\n",
    "        user_attributes = user_attributes.filter(col(\"usage_days\") >= num_events_threshold)\n",
    "\n",
    "    # Save the resulting DataFrame to a CSV file\n",
    "    print(f\"Saving processed data into {outcsv}...\")\n",
    "    user_attributes.write.csv(outcsv, header=True, mode=\"overwrite\")\n",
    "    print(f\"Data well saved into {outcsv}.\")\n",
    "\n",
    "    return user_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(userId=13176915433854, usage_days=11, mean_locs_per_day=3.8181818181818183, avg_Rg=0.006862897209384297, avg_latitude=-8.548269047619048, avg_longitude=26.74257928571429)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input folder\n",
    "SIMULATED_CDRS_DIR = os.path.join(DATA_DIR, \"processed_cdrs_output/\")\n",
    "num_events_threshold = 10\n",
    "\n",
    "# Generate user attributes\n",
    "outcsv =os.path.join(DATA_DIR, \"user_mobility_metrics_with_Rg.csv\")\n",
    "user_attributes_df = generate_basic_user_attributes_with_spark(SIMULATED_CDRS_DIR, outcsv, num_events_threshold=num_events_threshold)\n",
    "\n",
    "user_attributes_df.to_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between avg_Rg and mean_locs_per_day: 0.015569314979840142\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the saved user attributes\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "user_attributes_df = spark.read.csv(outcsv, header=True, inferSchema=True)\n",
    "\n",
    "# Explore correlation between avg_Rg and mean_locs_per_day\n",
    "correlation = user_attributes_df.stat.corr(\"avg_Rg\", \"mean_locs_per_day\")\n",
    "\n",
    "print(f\"Correlation between avg_Rg and mean_locs_per_day: {correlation}\")\n",
    "\n",
    "# Plot the correlation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert Spark DataFrame to Pandas for visualization\n",
    "user_attributes_pd = user_attributes_df.toPandas()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter( user_attributes_pd['avg_Rg'],user_attributes_pd['mean_locs_per_day'], alpha=0.7)\n",
    "plt.title(f\"Correlation between Avg. Radius of Gyration and Avg. Locations/Day\\nCorrelation Coefficient: {correlation:.2f}\")\n",
    "plt.xlabel(\"Average Locations per Day\")\n",
    "plt.ylabel(\"Average Radius of Gyration\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task-4.** What large dataset challenges did you face and how did you solve them. Please explain the decisions you made and why you made them. For example, if you sampled the data, how much of the data did you sample? [ 300 words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Challenges\n",
    "\n",
    "   - **Date Formatting Issues:**\n",
    "        The dataset contained inconsistent or non-standard date formats, causing errors during parsing.\n",
    "        Spark’s built-in functions often struggled to handle custom date formats or required additional configuration to correctly parse datetime columns. \n",
    "        To solve it I utilized Spark’s date_format and to_date functions to normalize and standardize all datetime columns at the preprocessing stage.\n",
    "        Applied UDFs (User-Defined Functions) where necessary for custom transformations.\n",
    "\n",
    "   - **Spark Compatibility:**\n",
    "        Some Python functions or libraries (e.g., datetime for advanced date manipulation) were not directly compatible with Spark DataFrames.\n",
    "        Complex operations, such as calculating derived mobility metrics, required creative solutions using Spark’s SQL functions and window operations.\n",
    "        To solve it I replaced Python-based computations with Spark SQL functions to leverage distributed processing.\n",
    "        Used Spark’s Window functions to calculate metrics like radius of gyration and mobility attributes efficiently.\n",
    "\n",
    "   - **Java-Related Problems:**\n",
    "        Spark relies on Java Virtual Machine (JVM), and Java errors surfaced during memory-intensive tasks or operations involving large shuffles (e.g., group-by operations across user data).\n",
    "        Version mismatches between Spark, Java, and Hadoop libraries occasionally caused runtime errors.\n",
    "        I solve it by increasing memory allocation for Spark jobs by adjusting JVM parameters (spark.executor.memory and spark.driver.memory).\n",
    "        Avoided operations that required excessive data shuffling by carefully partitioning and re-partitioning data based on user IDs.\n",
    "\n",
    "   - **Slowness with Pandas:**\n",
    "        Pandas struggled with memory-intensive operations, such as reading multiple large CSV files or performing transformations on large subsets of data.\n",
    "        Debugging and prototyping with Pandas became a bottleneck when transitioning to larger datasets.\n",
    "        To managed it, I use performed initial prototyping with a small subset of data using Pandas but transitioned fully to Spark for larger-scale processing.\n",
    "        Spark’s lazy evaluation and distributed nature significantly improved processing speed and reduced memory consumption.\n",
    "\n",
    "   - **File I/O Overheads:**\n",
    "        With nearly 20,000 CSV files and 12GB of data, file reading and writing added significant overhead.\n",
    "        Ensuring proper directory structures for outputs was also critical to avoid accidental overwrites.\n",
    "        For that, Read and processed smaller subsets of the dataset in batches during debugging to avoid overwhelming the system.\n",
    "        Configured output directories to store intermediate and final results separately, reducing potential conflicts and ensuring modularity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The decisions made\n",
    "\n",
    "- **Create my function to format the date instead of using Spark UDF:**\n",
    "\n",
    "\n",
    "- **Using Spark instead of using Pandas to generate user attributes:**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the size of my dataset if use the whole dataset of 12 GB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_basic_user_attributes_with_pandas(df, outcsv, num_events_threshold=None):\n",
    "    \"\"\"\n",
    "        In this funciton, we generate some basic user attributes\n",
    "        to help further explore the data and also report on\n",
    "        individual mobility metrics.\n",
    "        :param df: Pandas DataFrame with multiple user data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    # get userid col name from  MISC_PROCESSING_PARAMS\n",
    "    userid = None\n",
    "    # generate a list of unique userid's\n",
    "    user_list = None\n",
    "    # initialize an empty list to hold user  data\n",
    "    user_data = None\n",
    "\n",
    "    # Loop through all users and generate their attributes\n",
    "#     YOUR CODE\n",
    "#         # Filter the input df so that we only get data for this user\n",
    "#         df_user = None\n",
    "\n",
    "#         if num_events_threshold:\n",
    "#             if df_user.shape[0] < num_events_threshold:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 # call the get_basic_user_mob_attributes function here\n",
    "#                 # YOUR CODE\n",
    "#         else:\n",
    "#              # call the get_basic_user_mob_attributes function here\n",
    "#             # YOUR CODE\n",
    "\n",
    "#         # get the attributes\n",
    "#         # create a dictionary with the following keys: 'userid', 'usage_days', 'mean_locs_day'\n",
    "#         # use appropriate numpy functions to compute  mean as required and set them as values\n",
    "#         # in the dict\n",
    "#         user_att = None\n",
    "#         # add user_att to the user_data list\n",
    "#         #YOUR CODE\n",
    "\n",
    "    print(\"=\"*40)\n",
    "    print(\"This is the top  10  rows of the DataFrame.\")\n",
    "    print(\"=\"*40)\n",
    "    print()\n",
    "    # please print only the head of  the DataFrame below\n",
    "    # YOUR CODE\n",
    "\n",
    "    # create DataFrame using user_data and save it to file (2 lines of code)\n",
    "    # YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
